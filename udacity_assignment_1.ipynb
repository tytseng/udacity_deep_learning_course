{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import urlretrieve\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified notMNIST_large.tar.gz\n",
      "Found and verified notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'http://yaroslavvb.com/upload/notMNIST/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(filename):\n",
    "    filename, _ = urlretrieve(url + filename, filename)\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print 'Found and verified', filename\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notMNIST_large.tar.gz\n",
      "notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print train_filename\n",
    "print test_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for notMNIST_large. This may take a while. Please wait.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Expected 4 folders, one per class. Found 10 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d021a35ebc45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata_folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtrain_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mtest_folders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-d021a35ebc45>\u001b[0m in \u001b[0;36mextract\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     13\u001b[0m     raise Exception(\n\u001b[0;32m     14\u001b[0m       'Expected %d folders, one per class. Found %d instead.' % (\n\u001b[1;32m---> 15\u001b[1;33m         num_classes, len(data_folders)))\n\u001b[0m\u001b[0;32m     16\u001b[0m   \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata_folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Expected 4 folders, one per class. Found 10 instead."
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "def extract(filename):\n",
    "  tar = tarfile.open(filename)\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "  sys.stdout.flush()\n",
    "  tar.extractall()\n",
    "  tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root)) if d != '.DS_Store']\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "\n",
    "train_folders = extract(train_filename)\n",
    "test_folders = extract(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem1\n",
    "Let's take a peek at some of the data to make sure it looks sensible. Each exemplar should be an image of a character A through J rendered in a different font. Display a sample of the images that we just downloaded. Hint: you can use the package IPython.display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABqklEQVR4nHWRO2tUURSFv/OYGSOK\nEERBBRUSC8EihThC1HJEQUzhY7AwWPho/AU2FpJCsLCwCaSQCMFGEW3ESkWxiYUYIZUWghIuAyP4\nmn3uspjM9V4zruacsxd7nbXXhgKesV/HCJQrBRyt+kn+A8crfd2GG8Z5JmS6Utb1pdspEufIh4qO\nLClJ+8s2BggcVZLpFnEYufDuvUwfN6615Bj9PXVDltSujApA5EKv1lRuery20/PyAWFRph97C0ur\np8/HmndJ95GtO/1va+BaNgJ7fsr0oVFlHSzPET2PZEnV9PEc0BFCoK1kulclI3c+e5xj9JNMnR3V\nZdVWbhIgcltmulpOKXBCE3gINCXTa1ey5JnXSpZlWZZ1cuXSof6vEXD51qnZJ5sSELqty0qx/aKk\nelGrHjw7u0r6srnQ9bx5Sj3GGGNsMC8zTQ+m8YzrzOARaCk3PRsME7neKZboqC3K1NuHBx9i8ucf\nfqv7PusavQVI8Sy1ECBwXIf/BubZnsm0vB5HnGTLDNMx8bbr5LRrd/q+NInGLz3fkDApl5R0kEBg\nRqakfi3/A3tyu8ojQ17tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABKElEQVR4nHXRPU4DMRAF4DceBykS\nHISKn1U4Aw11FBoaroFIhSjpaaiyoqOnoSEH4BK0ILQSwet5FLZ3idh9leVPY3vGuIETjIV3kFFt\neS/ixioDa8WIkoFP06yiqqrqeuQPn/cgALq780IIoPWvZx+gM3cEAAhvAuZKsuUMKqIrpiyh0qHF\nCl60ZohmFlteJ03ISlRqhlRogUt46XAGvyqWVaXgAR65sRJayyV8RqseuBULvEqtAHF90mg3GN0F\naHqbkHK6nsRC8fCFAlB83nn/+jPSzzQfK7gj2lfmTVeQJPtlXhV0/Ve47gMLNrGciogmndA96Hjq\nrFTafrLS5/8Q8RJlIlsho8U5wMFEswUmw2gWz+GHK422wASDaLaZpx6HLvy+SPYLx4dMEQPVVH8A\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(filename=\"/home/tzeng/Repos/seaborn-practice/notMNIST_large/A/QmF1ZXJCb2RULVJlZ3Uub3Rm.png\"))\n",
    "display(Image(filename=\"/home/tzeng/Repos/seaborn-practice/notMNIST_large/B/a29ydW5pc2hpLnR0Zg==.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tzeng/Repos/seaborn-practice/notMNIST_large/A', '/home/tzeng/Repos/seaborn-practice/notMNIST_large/B', '/home/tzeng/Repos/seaborn-practice/notMNIST_large/C', '/home/tzeng/Repos/seaborn-practice/notMNIST_large/D']\n",
      "['/home/tzeng/Repos/seaborn-practice/notMNIST_small/A', '/home/tzeng/Repos/seaborn-practice/notMNIST_small/B', '/home/tzeng/Repos/seaborn-practice/notMNIST_small/C', '/home/tzeng/Repos/seaborn-practice/notMNIST_small/D']\n"
     ]
    }
   ],
   "source": [
    "root_l = '/home/tzeng/Repos/seaborn-practice/notMNIST_large/'\n",
    "root_s = '/home/tzeng/Repos/seaborn-practice/notMNIST_small/'\n",
    "classes = ['A', 'B', 'C', 'D']\n",
    "train_folders = map(lambda d: os.path.join(root_l, d), classes)\n",
    "test_folders = map(lambda d: os.path.join(root_s, d), classes)\n",
    "\n",
    "print train_folders\n",
    "print test_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tzeng/Repos/seaborn-practice/notMNIST_large/A\n",
      "('Could not read:', '/home/tzeng/Repos/seaborn-practice/notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png', ':', IOError('cannot identify image file',), \"- it's ok, skipping.\")\n",
      "('Could not read:', '/home/tzeng/Repos/seaborn-practice/notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png', ':', IOError('cannot identify image file',), \"- it's ok, skipping.\")\n",
      "('Could not read:', '/home/tzeng/Repos/seaborn-practice/notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png', ':', IOError('cannot identify image file',), \"- it's ok, skipping.\")\n",
      "/home/tzeng/Repos/seaborn-practice/notMNIST_large/B\n",
      "('Could not read:', '/home/tzeng/Repos/seaborn-practice/notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png', ':', IOError('cannot identify image file',), \"- it's ok, skipping.\")\n",
      "/home/tzeng/Repos/seaborn-practice/notMNIST_large/C\n",
      "/home/tzeng/Repos/seaborn-practice/notMNIST_large/D\n",
      "('Could not read:', '/home/tzeng/Repos/seaborn-practice/notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png', ':', IOError('cannot identify image file',), \"- it's ok, skipping.\")\n",
      "('Full dataset tensor:', (211643, 28, 28))\n",
      "('Mean:', -0.083859786)\n",
      "('Standard deviation:', 0.45162633)\n",
      "('Labels:', (211643,))\n",
      "/home/tzeng/Repos/seaborn-practice/notMNIST_small/A\n",
      "('Could not read:', '/home/tzeng/Repos/seaborn-practice/notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png', ':', IOError('cannot identify image file',), \"- it's ok, skipping.\")\n",
      "/home/tzeng/Repos/seaborn-practice/notMNIST_small/B\n",
      "/home/tzeng/Repos/seaborn-practice/notMNIST_small/C\n",
      "/home/tzeng/Repos/seaborn-practice/notMNIST_small/D\n",
      "('Full dataset tensor:', (7491, 28, 28))\n",
      "('Mean:', -0.0794947)\n",
      "('Standard deviation:', 0.45531201)\n",
      "('Labels:', (7491,))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load(data_folders, min_num_images, max_num_images):\n",
    "  dataset = np.ndarray(\n",
    "    shape=(max_num_images, image_size, image_size), dtype=np.float32)\n",
    "    # list with len(max_num_images), each is matrix with row=col=image_size\n",
    "  labels = np.ndarray(shape=(max_num_images), dtype=np.int32)\n",
    "  label_index = 0\n",
    "  image_index = 0\n",
    "  for folder in data_folders:\n",
    "    print(folder)\n",
    "    for image in os.listdir(folder):\n",
    "      if image_index >= max_num_images:\n",
    "        raise Exception('More images than expected: %d >= %d' % (\n",
    "          image_index, max_num_images))\n",
    "      image_file = os.path.join(folder, image)\n",
    "      try:\n",
    "        image_data = (ndimage.imread(image_file).astype(float) -\n",
    "                      pixel_depth / 2) / pixel_depth\n",
    "        # range of image data (0,255) -> (-0.5, 0.5)\n",
    "        if image_data.shape != (image_size, image_size):\n",
    "          raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "        dataset[image_index, :, :] = image_data\n",
    "        labels[image_index] = label_index\n",
    "        image_index += 1\n",
    "      except IOError as e:\n",
    "        print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    label_index += 1\n",
    "  num_images = image_index\n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  labels = labels[0:num_images]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' % (\n",
    "        num_images, min_num_images))\n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  print('Labels:', labels.shape)\n",
    "  return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = load(train_folders, 180000, 220000)\n",
    "test_dataset, test_labels = load(test_folders, 7200, 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem2\n",
    "Let's verify that the data still looks good. Displaying a sample of the labels and images from the ndarray. Hint: you can use matplotlib.pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#print train_dataset[0]\n",
    "print train_labels[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomize the order of dataset\n",
    "np.random.seed(133)\n",
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem3\n",
    "Convince yourself that the data is still good after shuffling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.0254902 ,  0.47647059,  0.43333334,  0.24509804, -0.14313726,\n",
       "        -0.5       , -0.49215686, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.49607843, -0.5       , -0.41764706,\n",
       "         0.42941177,  0.49607843,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.04901961, -0.5       , -0.49215686, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.48823529, -0.49607843, -0.24509804,\n",
       "         0.5       ,  0.5       ,  0.49215686,  0.48823529,  0.48823529,\n",
       "         0.5       , -0.17450981, -0.5       , -0.48823529, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.48823529, -0.5       ,  0.08431373,\n",
       "         0.5       ,  0.37450981,  0.5       ,  0.49607843,  0.48431373,\n",
       "         0.49607843,  0.25686276, -0.5       , -0.49607843, -0.49607843,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.49215686, -0.5       , -0.32745099,  0.49607843,\n",
       "        -0.09215686, -0.46470588,  0.0254902 ,  0.5       ,  0.48039216,\n",
       "         0.5       ,  0.44901961, -0.40980393, -0.5       , -0.49607843,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.49215686, -0.5       ,  0.27254903,  0.3509804 ,\n",
       "        -0.5       , -0.49607843, -0.5       ,  0.07647059,  0.5       ,\n",
       "         0.49215686,  0.49607843, -0.27254903, -0.5       , -0.48823529,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.48823529, -0.5       , -0.18627451,  0.5       ,  0.2372549 ,\n",
       "        -0.49607843, -0.48431373, -0.49215686, -0.5       , -0.00588235,\n",
       "         0.49607843,  0.5       , -0.19411765, -0.5       , -0.48431373,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.48823529, -0.5       ,  0.1627451 ,  0.49607843,  0.24117647,\n",
       "        -0.5       , -0.48823529, -0.49607843, -0.49607843, -0.5       ,\n",
       "         0.2764706 ,  0.5       , -0.12352941, -0.5       , -0.48431373,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       ,  0.2647059 ,  0.5       ,  0.24509804,\n",
       "        -0.5       , -0.48823529, -0.5       , -0.48431373, -0.49215686,\n",
       "        -0.02156863,  0.5       , -0.03333334, -0.5       , -0.48431373,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       ,  0.26862746,  0.5       ,  0.24509804,\n",
       "        -0.5       , -0.48823529, -0.5       , -0.48823529, -0.5       ,\n",
       "        -0.16666667,  0.5       ,  0.06470589, -0.5       , -0.48823529,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       ,  0.26862746,  0.5       ,  0.24509804,\n",
       "        -0.49607843, -0.48431373, -0.5       , -0.48431373, -0.5       ,\n",
       "        -0.19803922,  0.5       ,  0.15882353, -0.5       , -0.49215686,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       ,  0.28039217,  0.5       ,  0.2372549 ,\n",
       "        -0.5       , -0.49607843, -0.48823529, -0.47254902, -0.49215686,\n",
       "        -0.1509804 ,  0.5       ,  0.26078433, -0.5       , -0.49215686,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.49215686,  0.31568629,  0.5       ,  0.27254903,\n",
       "        -0.4137255 , -0.45686275, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.02156863,  0.5       ,  0.3392157 , -0.48431373, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.49215686,\n",
       "        -0.49607843, -0.37843138,  0.44901961,  0.5       ,  0.48431373,\n",
       "         0.4254902 ,  0.32352942,  0.14313726, -0.10784314, -0.34705883,\n",
       "         0.24901961,  0.5       ,  0.39803922, -0.40980393, -0.5       ,\n",
       "        -0.49607843, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.5       , -0.48823529,\n",
       "        -0.5       ,  0.00980392,  0.5       ,  0.48823529,  0.5       ,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.48431373,\n",
       "         0.47254902,  0.5       ,  0.47647059, -0.3392157 , -0.5       ,\n",
       "        -0.49215686, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.49215686, -0.49607843,\n",
       "        -0.37450981,  0.44509804,  0.49215686,  0.49607843,  0.37843138,\n",
       "         0.00588235,  0.00196078,  0.06470589,  0.31176472,  0.48431373,\n",
       "         0.5       ,  0.49215686,  0.5       , -0.2647059 , -0.5       ,\n",
       "        -0.48823529, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.5       , -0.49215686, -0.5       ,\n",
       "         0.13137256,  0.5       ,  0.47647059,  0.5       ,  0.23333333,\n",
       "        -0.5       , -0.5       , -0.5       , -0.49215686, -0.32352942,\n",
       "         0.13529412,  0.49215686,  0.5       , -0.10784314, -0.49607843,\n",
       "        -0.48431373, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.49215686, -0.5       , -0.34705883,\n",
       "         0.47647059,  0.49215686,  0.48431373,  0.5       ,  0.26078433,\n",
       "        -0.48431373, -0.47254902, -0.48823529, -0.49607843, -0.5       ,\n",
       "        -0.48039216,  0.39411765,  0.5       ,  0.1509804 , -0.5       ,\n",
       "        -0.48431373, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.48431373, -0.5       , -0.08039216,\n",
       "         0.5       ,  0.48431373,  0.49215686,  0.5       ,  0.31960785,\n",
       "        -0.49215686, -0.5       , -0.49607843, -0.5       , -0.48823529,\n",
       "        -0.5       ,  0.2764706 ,  0.5       ,  0.44509804, -0.37450981,\n",
       "        -0.5       , -0.47647059, -0.49215686, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.5       , -0.48823529, -0.5       ,  0.15490197,\n",
       "         0.5       ,  0.48431373,  0.47647059,  0.49215686,  0.29215688,\n",
       "        -0.49607843, -0.49607843, -0.5       , -0.5       , -0.48823529,\n",
       "        -0.49607843,  0.12352941,  0.49607843,  0.5       ,  0.26078433,\n",
       "        -0.37058824, -0.5       , -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.49607843, -0.5       , -0.47254902,  0.34705883,\n",
       "         0.5       ,  0.49215686,  0.5       ,  0.5       ,  0.27254903,\n",
       "        -0.5       , -0.49215686, -0.5       , -0.5       , -0.48431373,\n",
       "        -0.5       , -0.13529412,  0.5       ,  0.48431373,  0.5       ,\n",
       "         0.4254902 ,  0.07647059, -0.30784315, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.49215686, -0.5       , -0.33137256,  0.48039216,\n",
       "         0.49607843,  0.5       ,  0.17058824, -0.20588236, -0.37843138,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.49215686,\n",
       "        -0.5       , -0.40196079,  0.44509804,  0.5       ,  0.48823529,\n",
       "         0.5       ,  0.5       ,  0.48823529,  0.12745099, -0.48039216,\n",
       "        -0.49607843, -0.5       , -0.5       ],\n",
       "       [-0.5       , -0.48431373, -0.5       , -0.08039216,  0.5       ,\n",
       "         0.48823529, -0.11176471, -0.5       , -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       ,  0.20196079,  0.5       ,  0.48431373,\n",
       "         0.49607843,  0.48823529,  0.5       ,  0.5       , -0.22941177,\n",
       "        -0.49607843, -0.48823529, -0.5       ],\n",
       "       [-0.49215686, -0.48431373, -0.5       ,  0.25294119,  0.5       ,\n",
       "         0.1509804 , -0.5       , -0.48431373, -0.48823529, -0.49607843,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.48431373, -0.5       , -0.06470589,  0.5       ,  0.48823529,\n",
       "         0.5       ,  0.5       ,  0.48039216,  0.49215686,  0.04901961,\n",
       "        -0.5       , -0.48431373, -0.49215686],\n",
       "       [-0.5       , -0.5       , -0.2764706 ,  0.48431373,  0.5       ,\n",
       "        -0.1627451 , -0.48823529, -0.48431373, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       , -0.2764706 ,  0.5       ,  0.49607843,\n",
       "         0.5       ,  0.5       ,  0.48823529,  0.5       ,  0.24509804,\n",
       "        -0.43725491, -0.5       , -0.5       ],\n",
       "       [-0.43725491, -0.26078433,  0.31568629,  0.48823529,  0.49607843,\n",
       "        -0.01764706, -0.5       , -0.48823529, -0.5       , -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       , -0.36666667,  0.48039216,  0.5       ,\n",
       "         0.49607843,  0.5       ,  0.5       ,  0.5       ,  0.49215686,\n",
       "         0.4254902 ,  0.30784315, -0.17843138],\n",
       "       [ 0.37058824,  0.5       ,  0.5       ,  0.5       ,  0.5       ,\n",
       "         0.46862745, -0.30784315, -0.5       , -0.49215686, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       , -0.25686276,  0.5       ,  0.49607843,\n",
       "         0.5       ,  0.5       ,  0.5       ,  0.5       ,  0.49607843,\n",
       "         0.5       ,  0.35882354, -0.33137256],\n",
       "       [ 0.12745099,  0.15882353,  0.19803922,  0.2647059 ,  0.32745099,\n",
       "         0.47254902, -0.11960784, -0.5       , -0.48431373, -0.5       ,\n",
       "        -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        -0.49215686, -0.5       , -0.26862746,  0.36274511,  0.49607843,\n",
       "         0.49607843,  0.5       ,  0.5       ,  0.5       ,  0.47647059,\n",
       "         0.14705883, -0.40588236, -0.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem4\n",
    "Another check: we expect the data to be balanced across classes. Verify that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 52912, 1: 52911, 3: 52911, 0: 52909})\n",
      "Counter({1: 1873, 2: 1873, 3: 1873, 0: 1872})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt_label = Counter()\n",
    "for l in train_labels:\n",
    "    cnt_label[l] += 1\n",
    "print cnt_label\n",
    "\n",
    "cnt_test_label = Counter()\n",
    "for l in test_labels:\n",
    "    cnt_test_label[l] += 1\n",
    "print cnt_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training', (100000, 28, 28), (100000,))\n",
      "('Validation', (10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "# create validation dataset\n",
    "train_size = 100000\n",
    "valid_size = 10000\n",
    "\n",
    "valid_dataset = train_dataset[:valid_size,:,:]\n",
    "valid_labels = train_labels[:valid_size]\n",
    "sub_train_dataset = train_dataset[valid_size:valid_size+train_size,:,:]\n",
    "sub_train_labels = train_labels[valid_size:valid_size+train_size]\n",
    "print('Training', sub_train_dataset.shape, sub_train_labels.shape)\n",
    "print('Validation', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': sub_train_dataset,\n",
    "    'train_labels': sub_train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compressed pickle size:', 368922254)\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem 5\n",
    "By construction, this dataset might contain a lot of overlapping samples, including training data that's also contained in the validation and test set! Overlap between training and test can skew the results if you expect to use your model in an environment where there is never an overlap, but are actually ok if you expect to see training samples recur when you use it. Measure how much overlap there is between training, validation and test samples.\n",
    "\n",
    "Optional questions:\n",
    "- What about near duplicates between datasets? (images that are almost identical)\n",
    "- Create a sanitized validation and test set, and compare your accuracy on those in subsequent assignments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 784)\n"
     ]
    }
   ],
   "source": [
    "# reshape 28*28 matrix to 784*1\n",
    "\n",
    "train_dataset_1 = np.ndarray(shape=(train_size, image_size*image_size), dtype=np.float32)\n",
    "for ix, m in enumerate(sub_train_dataset):\n",
    "    train_dataset_1[ix, :] = m.reshape(image_size*image_size,)\n",
    "print train_dataset_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "[0 3 1 2 2 3 2 3 3 2]\n"
     ]
    }
   ],
   "source": [
    "print sub_train_labels.shape\n",
    "print sub_train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from scipy import stats\n",
    "\n",
    "stats.pearsonr(train_dataset_1[0], train_dataset_1[1])\n",
    "\n",
    "corr_dict = {}\n",
    "for i in xrange(train_size-1):\n",
    "    for j in xrange(i+1, train_size):\n",
    "        corr_tuple = stats.pearsonr(train_dataset_1[i], train_dataset_1[j])\n",
    "        if corr_tuple[0] == 1.0:\n",
    "            print (i,j)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.48823529 -0.5        -0.28431374  0.0254902  -0.1627451  -0.47254902\n",
      " -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.48823529 -0.5        -0.21764706  0.46078432  0.5         0.5\n",
      "  0.28431374 -0.34705883 -0.5        -0.49215686 -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.49215686 -0.5        -0.31568629  0.44901961  0.5         0.48039216\n",
      "  0.48823529  0.5         0.42156863 -0.31960785 -0.5        -0.49215686\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.49607843 -0.5        -0.47647059  0.2764706   0.5\n",
      "  0.48823529  0.5         0.5         0.47647059  0.5         0.04509804\n",
      " -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.48823529 -0.5         0.00588235\n",
      "  0.5         0.48431373  0.5         0.5         0.5         0.49215686\n",
      "  0.5         0.31960785 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      " -0.26078433  0.48039216  0.5         0.5         0.49607843  0.49607843\n",
      "  0.5         0.49607843  0.5         0.48039216 -0.30784315 -0.5\n",
      " -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.49607843 -0.5        -0.49607843  0.27254903  0.5         0.48823529\n",
      "  0.5         0.49215686  0.5         0.5         0.5         0.48431373\n",
      "  0.5        -0.06862745 -0.5        -0.48823529 -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.48431373 -0.5        -0.10392157  0.5\n",
      "  0.48823529  0.49607843  0.5         0.4254902   0.37450981  0.5\n",
      "  0.49607843  0.48823529  0.5         0.22156863 -0.5        -0.49215686\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.49607843 -0.5\n",
      " -0.40196079  0.39019608  0.5         0.49607843  0.48823529  0.5\n",
      " -0.14705883 -0.09607843  0.5         0.48431373  0.49215686  0.5\n",
      "  0.4137255  -0.40196079 -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.48823529 -0.5         0.0882353   0.5         0.48823529  0.48823529\n",
      "  0.5         0.13137256 -0.5        -0.30000001  0.48431373  0.5\n",
      "  0.49607843  0.48823529  0.5        -0.18627451 -0.5        -0.48823529\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.48823529 -0.5        -0.26862746  0.5         0.5\n",
      "  0.48823529  0.5         0.31176472 -0.44901961 -0.5        -0.49607843\n",
      "  0.31568629  0.5         0.49215686  0.48823529  0.5         0.1        -0.5\n",
      " -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.49607843 -0.5         0.24509804\n",
      "  0.5         0.48431373  0.5         0.45686275 -0.31176472 -0.5\n",
      " -0.47647059 -0.5         0.0254902   0.5         0.48431373  0.49215686\n",
      "  0.5         0.3392157  -0.47647059 -0.5        -0.49607843 -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      " -0.5        -0.07647059  0.5         0.48823529  0.48823529  0.5\n",
      " -0.03333334 -0.5        -0.48431373 -0.48823529 -0.5        -0.24509804\n",
      "  0.5         0.5         0.49607843  0.49607843  0.5        -0.26078433\n",
      " -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.49215686 -0.5        -0.36666667  0.42941177  0.5\n",
      "  0.48823529  0.5         0.26862746 -0.47647059 -0.5        -0.5\n",
      " -0.49607843 -0.5        -0.46862745  0.37058824  0.5         0.49215686\n",
      "  0.48823529  0.5         0.07254902 -0.5        -0.48823529 -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.48823529 -0.5\n",
      "  0.15490197  0.5         0.48431373  0.5         0.49607843 -0.2647059\n",
      " -0.5        -0.48431373 -0.49607843 -0.49607843 -0.48431373 -0.5         0.1\n",
      "  0.5         0.48431373  0.49215686  0.5         0.35490197 -0.44901961\n",
      " -0.5        -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      " -0.48823529 -0.5        -0.17450981  0.5         0.49215686  0.48431373\n",
      "  0.5         0.06862745 -0.5        -0.48823529 -0.5        -0.5        -0.5\n",
      " -0.48823529 -0.5        -0.20588236  0.5         0.49607843  0.5\n",
      "  0.49215686  0.5        -0.21372549 -0.5        -0.48823529 -0.5        -0.5\n",
      " -0.5        -0.49607843 -0.5        -0.43725491  0.35882354  0.5\n",
      "  0.49215686  0.49607843  0.5         0.34313726 -0.13137256 -0.40196079\n",
      " -0.48431373 -0.49215686 -0.47647059 -0.40196079 -0.28823531 -0.02156863\n",
      "  0.49215686  0.5         0.5         0.48823529  0.5         0.11960784\n",
      " -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.48431373\n",
      " -0.5         0.0254902   0.5         0.48431373  0.5         0.5         0.5\n",
      "  0.5         0.5         0.45686275  0.35882354  0.32745099  0.37450981\n",
      "  0.44901961  0.5         0.5         0.5         0.5         0.5\n",
      "  0.49607843  0.5         0.39411765 -0.41764706 -0.5        -0.49607843\n",
      " -0.5        -0.49215686 -0.5        -0.30392158  0.46470588  0.5\n",
      "  0.49607843  0.5         0.5         0.5         0.49215686  0.48823529\n",
      "  0.5         0.5         0.5         0.5         0.5         0.49607843\n",
      "  0.48039216  0.48823529  0.5         0.5         0.5         0.49215686\n",
      "  0.5        -0.1627451  -0.5        -0.48823529 -0.5        -0.49607843\n",
      " -0.5         0.22156863  0.5         0.48823529  0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.49215686  0.48823529  0.48431373\n",
      "  0.48039216  0.48039216  0.48823529  0.5         0.5         0.49607843\n",
      "  0.5         0.5         0.48823529  0.5         0.17450981 -0.5\n",
      " -0.48823529 -0.48431373 -0.5        -0.13529412  0.5         0.48823529\n",
      "  0.5         0.48823529  0.48431373  0.48431373  0.48823529  0.48823529\n",
      "  0.49215686  0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.42156863  0.29215688  0.49215686  0.5         0.5         0.49607843\n",
      "  0.5         0.44117647 -0.40196079 -0.5        -0.5        -0.45686275\n",
      "  0.3509804   0.5         0.49215686  0.49607843  0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.49607843  0.44901961  0.3509804\n",
      "  0.19411765  0.0254902  -0.20196079 -0.4254902  -0.5         0.25686276\n",
      "  0.5         0.48823529  0.5         0.49215686  0.5        -0.11568628\n",
      " -0.5        -0.5        -0.03333334  0.5         0.48823529  0.49607843\n",
      "  0.5         0.13529412 -0.06862745 -0.06862745 -0.1        -0.14705883\n",
      " -0.24509804 -0.31960785 -0.39411765 -0.48431373 -0.5        -0.5        -0.5\n",
      " -0.48823529 -0.5        -0.21764706  0.5         0.49607843  0.5\n",
      "  0.48431373  0.5         0.10392157 -0.5        -0.39411765  0.39411765\n",
      "  0.5         0.48823529  0.5         0.35490197 -0.44901961 -0.5\n",
      " -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.48823529 -0.48431373 -0.48431373 -0.49215686 -0.5        -0.48823529\n",
      "  0.28039217  0.5         0.49215686  0.48823529  0.5         0.20588236\n",
      " -0.5         0.0254902   0.5         0.48823529  0.48431373  0.5\n",
      " -0.06470589 -0.5        -0.47254902 -0.48431373 -0.48431373 -0.48823529\n",
      " -0.48823529 -0.49215686 -0.49215686 -0.49607843 -0.5        -0.5        -0.5\n",
      " -0.5        -0.48823529 -0.5        -0.04901961  0.5         0.48823529\n",
      "  0.48431373  0.5         0.12352941 -0.5         0.2372549   0.5\n",
      "  0.48039216  0.5         0.30392158 -0.46862745 -0.5        -0.49607843\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      " -0.38627452  0.43725491  0.5         0.48039216  0.5        -0.17843138\n",
      " -0.5        -0.21372549  0.37058824  0.5         0.48039216 -0.25686276\n",
      " -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.48823529 -0.5         0.01372549  0.5         0.5\n",
      "  0.11176471 -0.5        -0.49607843 -0.5        -0.44901961 -0.21764706\n",
      " -0.22156863 -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.49607843 -0.5        -0.47254902\n",
      " -0.02156863 -0.0372549  -0.48823529 -0.5        -0.5       ] [-0.5        -0.5        -0.5        -0.48823529 -0.5        -0.28431374\n",
      "  0.5         0.49607843  0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.48823529\n",
      "  0.5         0.22156863 -0.5        -0.5        -0.5        -0.48431373\n",
      " -0.5        -0.09215686  0.5         0.48431373  0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.48823529  0.5         0.00196078 -0.5        -0.5        -0.5\n",
      " -0.48431373 -0.5         0.12352941  0.5         0.48431373  0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.49607843  0.5        -0.22156863 -0.5        -0.5        -0.5\n",
      " -0.49607843 -0.5         0.30000001  0.48431373  0.47647059  0.48431373\n",
      "  0.48431373  0.48431373  0.48431373  0.48431373  0.48431373  0.48431373\n",
      "  0.48431373  0.48431373  0.48431373  0.48431373  0.48431373  0.48431373\n",
      "  0.48431373  0.48431373  0.48431373  0.48431373  0.48823529  0.42941177\n",
      " -0.40196079 -0.5        -0.5        -0.49215686 -0.5        -0.37843138\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.31960785 -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      " -0.32352942  0.21372549  0.20196079  0.20980392  0.20588236  0.20588236\n",
      "  0.20588236  0.20588236  0.20588236  0.20588236  0.20588236  0.20588236\n",
      "  0.20588236  0.20588236  0.20588236  0.20588236  0.20588236  0.20588236\n",
      "  0.20588236  0.20588236  0.19803922  0.20588236 -0.05686275 -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.36274511 -0.33137256 -0.3392157\n",
      " -0.3392157  -0.33529413 -0.3392157  -0.32745099 -0.2647059  -0.2647059\n",
      " -0.2647059  -0.2647059  -0.2647059  -0.2647059  -0.2647059  -0.28039217\n",
      " -0.3392157  -0.33529413 -0.3392157  -0.3392157  -0.3392157  -0.33137256\n",
      " -0.34705883 -0.49215686 -0.5        -0.5        -0.49607843 -0.5\n",
      " -0.4254902   0.42941177  0.5         0.49215686  0.5         0.49215686\n",
      "  0.5         0.39803922 -0.16666667 -0.17450981 -0.17058824 -0.17450981\n",
      " -0.17450981 -0.16666667 -0.17450981 -0.01372549  0.5         0.49607843\n",
      "  0.5         0.5         0.49215686  0.5         0.3392157  -0.48823529\n",
      " -0.5        -0.5        -0.48823529 -0.5        -0.2647059   0.5\n",
      "  0.49215686  0.5         0.5         0.48431373  0.5         0.19411765\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.14705883  0.5         0.48431373  0.5         0.5         0.48431373\n",
      "  0.5         0.1509804  -0.5        -0.48823529 -0.5        -0.48431373\n",
      " -0.5        -0.06862745  0.49607843  0.48431373  0.5         0.5\n",
      "  0.48039216  0.49607843 -0.00588235 -0.48823529 -0.46862745 -0.48823529\n",
      " -0.48823529 -0.48823529 -0.47254902 -0.48823529  0.12745099  0.5\n",
      "  0.48431373  0.5         0.5         0.48431373  0.49607843 -0.06078431\n",
      " -0.5        -0.48431373 -0.5        -0.48823529 -0.5         0.13921569\n",
      "  0.5         0.48431373  0.5         0.5         0.49215686  0.5\n",
      " -0.20980392 -0.5        -0.48823529 -0.5        -0.5        -0.5\n",
      " -0.49607843 -0.5         0.30392158  0.5         0.49215686  0.5         0.5\n",
      "  0.49607843  0.5        -0.25686276 -0.5        -0.48823529 -0.5        -0.5\n",
      " -0.49215686  0.32745099  0.5         0.49215686  0.5         0.49607843\n",
      "  0.5         0.46862745 -0.38235295 -0.5        -0.49215686 -0.5        -0.5\n",
      " -0.49215686 -0.5        -0.40588236  0.45294118  0.5         0.49607843\n",
      "  0.5         0.49607843  0.5         0.43725491 -0.4254902  -0.5\n",
      " -0.49215686 -0.49215686 -0.5        -0.38627452  0.46470588  0.5\n",
      "  0.49607843  0.5         0.49215686  0.5         0.33137256 -0.49215686\n",
      " -0.5        -0.5        -0.5        -0.5        -0.48823529 -0.49607843\n",
      " -0.2372549   0.5         0.49215686  0.5         0.5         0.49215686\n",
      "  0.5         0.27254903 -0.5        -0.49607843 -0.5        -0.48823529\n",
      " -0.5        -0.20980392  0.5         0.49215686  0.5         0.5\n",
      "  0.48431373  0.5         0.14313726 -0.5        -0.48823529 -0.5        -0.5\n",
      " -0.5        -0.48039216 -0.5         0.05686275  0.5         0.48431373\n",
      "  0.5         0.5         0.48431373  0.49607843  0.01372549 -0.5\n",
      " -0.48431373 -0.5        -0.48431373 -0.5        -0.00588235  0.5\n",
      "  0.48431373  0.5         0.5         0.48431373  0.5        -0.06470589\n",
      " -0.5        -0.48431373 -0.5        -0.5        -0.48431373 -0.5\n",
      " -0.38235295  0.42941177  0.49607843  0.49607843  0.5         0.5\n",
      "  0.49607843  0.5        -0.2647059  -0.5        -0.48823529 -0.5\n",
      " -0.49215686 -0.5         0.19803922  0.5         0.48823529  0.5         0.5\n",
      "  0.49607843  0.5        -0.26078433 -0.49607843 -0.48039216 -0.48823529\n",
      " -0.48823529 -0.5        -0.42941177  0.28039217  0.5         0.49215686\n",
      "  0.5         0.5         0.49215686  0.49607843  0.35490197 -0.46862745\n",
      " -0.49607843 -0.49607843 -0.5        -0.5        -0.47647059  0.37843138\n",
      "  0.5         0.49215686  0.5         0.49607843  0.5         0.44509804\n",
      " -0.4137255  -0.5        -0.5        -0.5        -0.5        -0.25686276\n",
      "  0.31960785  0.5         0.49215686  0.5         0.5         0.5\n",
      "  0.48431373  0.5        -0.06470589 -0.5        -0.48431373 -0.5        -0.5\n",
      " -0.5        -0.34313726  0.49215686  0.5         0.49607843  0.5\n",
      "  0.48823529  0.5         0.2647059  -0.5        -0.46078432 -0.34313726\n",
      " -0.15882353  0.19411765  0.49607843  0.5         0.48823529  0.5         0.5\n",
      "  0.5         0.49215686  0.49607843  0.40980393 -0.42941177 -0.49607843\n",
      " -0.49607843 -0.5        -0.5        -0.5        -0.1627451   0.5\n",
      "  0.48823529  0.5         0.5         0.49607843  0.5         0.4254902\n",
      "  0.28823531  0.3509804   0.44901961  0.5         0.5         0.5\n",
      "  0.49215686  0.5         0.5         0.5         0.5         0.48431373\n",
      "  0.5        -0.13137256 -0.5        -0.48823529 -0.5        -0.5        -0.5\n",
      " -0.5         0.04117647  0.5         0.48431373  0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.48823529\n",
      "  0.48823529  0.49607843  0.5         0.5         0.5         0.5\n",
      "  0.48431373  0.5         0.19019608 -0.5        -0.48823529 -0.5        -0.5\n",
      " -0.5        -0.5        -0.5         0.2372549   0.5         0.48823529\n",
      "  0.5         0.5         0.5         0.5         0.49607843  0.48823529\n",
      "  0.49215686  0.49607843  0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.48431373  0.5         0.31176472 -0.43333334 -0.49607843\n",
      " -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.44117647\n",
      "  0.40196079  0.5         0.49607843  0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.49607843  0.48431373  0.5         0.3509804  -0.38627452\n",
      " -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.2764706   0.49215686  0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.49607843  0.48823529  0.5         0.5         0.22941177 -0.39019608\n",
      " -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.07254902  0.5         0.48823529  0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.49607843  0.49607843\n",
      "  0.49215686  0.49215686  0.5         0.5         0.48039216  0.06078431\n",
      " -0.48039216 -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5         0.15490197  0.5         0.48823529\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.44901961  0.1627451\n",
      " -0.30000001 -0.5        -0.5        -0.49215686 -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5         0.35490197\n",
      "  0.5         0.49607843  0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.42941177  0.34313726  0.21372549 -0.04509804\n",
      " -0.33137256 -0.5        -0.5        -0.49215686 -0.49607843 -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5       ]\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print train_dataset_1[0], train_dataset_1[1]\n",
    "print train_labels[0], train_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem 6\n",
    "Let's get an idea of what an off-the-shelf classifier can give you on this data. It's always good to check that there is something to learn, and that it's a problem that is not so trivial that a canned solution solves it.\n",
    "\n",
    "Train a simple model on this data using 50, 100, 1000 and 5000 training samples. Hint: you can use the LogisticRegression model from sklearn.linear_model.\n",
    "\n",
    "Optional question: train an off-the-shelf model on all the data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###First try with solver='newton-cg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='newton-cg')\n",
    "logreg.fit(train_dataset_1, sub_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7491, 28, 28)\n",
      "(7491, 784)\n",
      "(7491,)\n"
     ]
    }
   ],
   "source": [
    "print test_dataset.shape\n",
    "test_dataset_1 =  np.ndarray(shape=(7491, image_size*image_size), dtype=np.float32)\n",
    "for ix, m in enumerate(test_dataset):\n",
    "    test_dataset_1[ix, :] = m.reshape(image_size*image_size,)\n",
    "print test_dataset_1.shape\n",
    "print test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_output = logreg.predict(test_dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94927246028567613"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, pred_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'newton-cg',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###try with solver='lbfgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949939927913\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(solver='lbfgs',n_jobs=4)\n",
    "logreg2.fit(train_dataset_1, sub_train_labels)\n",
    "\n",
    "pred_output2 = logreg2.predict(test_dataset_1)\n",
    "print accuracy_score(test_labels, pred_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 4,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949806434388\n"
     ]
    }
   ],
   "source": [
    "logreg3 = LogisticRegression(C=0.5, solver='lbfgs',n_jobs=-1)\n",
    "logreg3.fit(train_dataset_1, sub_train_labels)\n",
    "\n",
    "pred_output3 = logreg3.predict(test_dataset_1)\n",
    "print accuracy_score(test_labels, pred_output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 4,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg3.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.33968209 -2.0619984  -2.70262316 -2.07753372]\n",
      "[100 100 100 100]\n"
     ]
    }
   ],
   "source": [
    "print logreg3.intercept_\n",
    "print logreg3.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949539447337\n",
      "[-1.35644493 -2.06403386 -2.71585575 -2.08151251]\n",
      "[200 200 200 200]\n"
     ]
    }
   ],
   "source": [
    "logreg4 = LogisticRegression(max_iter=200, solver='lbfgs',n_jobs=-1)\n",
    "logreg4.fit(train_dataset_1, sub_train_labels)\n",
    "\n",
    "pred_output4 = logreg4.predict(test_dataset_1)\n",
    "print accuracy_score(test_labels, pred_output4)\n",
    "print logreg4.intercept_\n",
    "print logreg4.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "loading = pickle.load(open('notMNIST.pickle'))\n",
    "for key,val in loading.items():\n",
    "    exec(key + '=val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(7491, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print train_dataset.shape\n",
    "print valid_dataset.shape\n",
    "print test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
